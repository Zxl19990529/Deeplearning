# 历年模型压缩与加速分类汇总

## Designing Structural Matrix
- 2015 
  - Fast multidimensional convolution in low-rank tensor formats via cross approximation
  - Structured transforms for small-footprint deep learning
  - Deep fried convnets
  - Fast neural networks with circulant projections
  - An exploration of parameter redundancy in deep networks with circulant projections
- 1991 
  - Generalized Displacement Structure for Block-Toeplitz, Toeplitz-block, and Toeplitz-derived Matrices
## Knowledge Distillation
- 2016 
  - Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer
  - Face model compression by distilling knowledge from neurons
- 2015 
  - Net2net: Accelerating learning via knowledge transfer
  - Bayesian dark knowledge
  - Distilling the knowledge in a neural network
- 2014 
  - Fitnets: Hints for thin deep nets
  - Do deep nets really need to be deep?
- 2006 
  - Model compression
## Low-Rank Factorization and Sparsity
- 2015
  - Convolutional neural networks with low-rank regularization
- 2014 
  - Speeding-up convolutional neural networks using fine-tuned cp- Decomposition
  - Speeding up convolutional neural networks with low rank expansions
  - Exploiting linear structure within convolutional networks for efficient Evaluation
- 2013 
  - Low-rank matrix factorization for deep neural network training with high-dimensional output targets
  - Predicting parameters in deep learning
  - Learning separable Filters
## Pruning and sharing
- 2016 
  - Pruning filters for efficient convnets
  - Learning structured sparsity in deep neural networks
  - Less is more: Towards compact cnns
  - Fast convnets using group-wise brain damage
- 2015 
  - Soft weight-sharing for neural network compression
  - Compressing neural networks with the hashing trick
  - Learning both weights and connections for efficient neural networks
  - Data-free parameter pruning for deep neural Networks
- 1993
  - Second order derivatives for network pruning: Optimal brain surgeon
- 1990 
  - Advances in neural information processing systems 2
- 1989
  - Comparing biases for minimal network construction with back-propagation

## Quantization and Binarization
- 2016
  - Loss-aware binarization of deep Networks
  - Deep neural networks are robust to weight binarization and other nonlinear distortions
  - Xnor-net:Imagenet classification using binary convolutional neural networks
  - Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1
  - Towards the limit of network quantization 
  - Deep compression: Compressing Neural networks with pruning, trained quantization and huffman coding
  - Quantized convolutional neural networks for mobile devices
- 2015
  - Neural networks with few multiplications
  - Binaryconnect: Training deep neural networks with binary weights during propagations
  - Deep learning with limited numerical precision
- 2014 
  - Compressing deep convolutional networks using vector quantization
- 2011
  - Improving the speed of nerual networks on cpus
## Transferred/Compact convolutional Filters
- 2016 
  - Squeezedet: Unified,small, low power fully convolutional neural networks for real-time object detection for autonomous driving
  - Inception-v4, inception-resnet and the impact of residual connections on learning.
  - Exploiting cyclic symmetry in convolutional neural networks
  - Multi-bias non-linear activation in deep neural networks
  - Understanding and improving convolutional neural networks via concatenated rectified linear units
  - Doubly convolutional neural Networks
  - Group equivariant convolutional netWorks